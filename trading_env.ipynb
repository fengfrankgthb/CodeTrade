{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn4/1KpdEiz7K1Jb3GtErn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fengfrankgthb/CodeTrade/blob/main/trading_env.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "class ForexTradingEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    A custom trading environment for EUR/USD that at each step:\n",
        "      - Observes a window of data (OHLC + indicators).\n",
        "      - Takes an action: choose among NO TRADE or combos of (direction, SL, TP).\n",
        "      - Computes reward based on PnL from that decision.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, window_size=30, sl_options=None, tp_options=None):\n",
        "        super(ForexTradingEnv, self).__init__()\n",
        "\n",
        "        # Store the dataframe containing prices and indicators\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.n_steps = len(self.df)\n",
        "\n",
        "        # Observation parameters\n",
        "        self.window_size = window_size\n",
        "\n",
        "        # Discretize SL and TP distances in pips or in price terms\n",
        "        # e.g. [10, 20, 30] pips from entry\n",
        "        self.sl_options = sl_options if sl_options else [60, 90, 120]\n",
        "        self.tp_options = tp_options if tp_options else [60, 90, 120]\n",
        "\n",
        "        # --- Construct a discrete action space with NO TRADE option ---\n",
        "        # Action 0 => No Trade\n",
        "        # Then for direction in [0=short, 1=long] and each sl, tp => next actions\n",
        "        self.action_map = [(None, None, None)]  # (None, None, None) => no trade\n",
        "        for direction in [0, 1]:  # 0=short, 1=long\n",
        "            for sl in self.sl_options:\n",
        "                for tp in self.tp_options:\n",
        "                    self.action_map.append((direction, sl, tp))\n",
        "\n",
        "        # The total number of discrete actions is 1 + 2 * len(sl_options) * len(tp_options)\n",
        "        self.action_space = spaces.Discrete(len(self.action_map))\n",
        "\n",
        "        # Number of features in the observation\n",
        "        self.num_features = self.df.shape[1]\n",
        "\n",
        "        # We'll return a window of these features as a 2D array\n",
        "        # shape = (window_size, num_features)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(self.window_size, self.num_features), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Internal state\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "        self.equity = 10000.0  # starting capital\n",
        "        self.max_slippage = 0.000  # example slippage\n",
        "        self.positions = []  # track open positions if you want; or one position at a time\n",
        "\n",
        "        # For logging\n",
        "        self.equity_curve = []\n",
        "        self.last_trade_info = None  # track the last trade details\n",
        "\n",
        "    def _get_observation(self):\n",
        "        \"\"\"\n",
        "        Returns the last 'window_size' observations as a 2D numpy array of shape (window_size, num_features).\n",
        "        If at the start (not enough history), pad with the earliest row or zeros.\n",
        "        \"\"\"\n",
        "        start = max(self.current_step - self.window_size, 0)\n",
        "        obs_df = self.df.iloc[start:self.current_step]\n",
        "\n",
        "        # If there's not enough data to fill 'window_size', pad with the earliest row\n",
        "        if len(obs_df) < self.window_size:\n",
        "            padding_rows = self.window_size - len(obs_df)\n",
        "            first_part = np.tile(obs_df.iloc[0].values, (padding_rows, 1))\n",
        "            obs_array = np.concatenate([first_part, obs_df.values], axis=0)\n",
        "        else:\n",
        "            obs_array = obs_df.values\n",
        "\n",
        "        return obs_array.astype(np.float32)\n",
        "\n",
        "    def _calculate_reward(self, direction, sl, tp):\n",
        "        \"\"\"\n",
        "        A very simplified approach:\n",
        "        - Immediately calculate PnL based on next bar's movement (or multiple bars) until SL/TP is hit.\n",
        "        - In a real scenario, you'd keep the position open for multiple steps.\n",
        "        \"\"\"\n",
        "        entry_price = self.df.loc[self.current_step, \"Close\"]\n",
        "\n",
        "        # If last step, no movement\n",
        "        if self.current_step >= self.n_steps - 1:\n",
        "            return 0.0\n",
        "\n",
        "        next_high = self.df.loc[self.current_step + 1, \"High\"]\n",
        "        next_low = self.df.loc[self.current_step + 1, \"Low\"]\n",
        "\n",
        "        # Convert pips to price distance\n",
        "        pip_value = 0.0001\n",
        "        sl_price_distance = sl * pip_value\n",
        "        tp_price_distance = tp * pip_value\n",
        "\n",
        "        # direction=1 => Long, direction=0 => Short\n",
        "        if direction == 1:\n",
        "            stop_loss = entry_price - sl_price_distance\n",
        "            take_profit = entry_price + tp_price_distance\n",
        "\n",
        "            # check if next_low < stop_loss => SL triggered\n",
        "            # check if next_high > take_profit => TP triggered\n",
        "            if next_low <= stop_loss and next_high >= take_profit:\n",
        "                # if both SL and TP are touched assume it's a loss\n",
        "                pnl = -sl_price_distance\n",
        "            elif next_low <= stop_loss:\n",
        "                pnl = -sl_price_distance\n",
        "            elif next_high >= take_profit:\n",
        "                pnl = tp_price_distance\n",
        "            else:\n",
        "                # use close for partial reward\n",
        "                next_close = self.df.loc[self.current_step + 1, \"Close\"]\n",
        "                pnl = next_close - entry_price\n",
        "        else:\n",
        "            # direction=0 => Short\n",
        "            stop_loss = entry_price + sl_price_distance\n",
        "            take_profit = entry_price - tp_price_distance\n",
        "\n",
        "            if next_high >= stop_loss and next_low <= take_profit:\n",
        "                if (stop_loss - entry_price) < (entry_price - take_profit):\n",
        "                    pnl = -sl_price_distance\n",
        "                else:\n",
        "                    pnl = tp_price_distance\n",
        "            elif next_high >= stop_loss:\n",
        "                pnl = -sl_price_distance\n",
        "            elif next_low <= take_profit:\n",
        "                pnl = tp_price_distance\n",
        "            else:\n",
        "                next_close = self.df.loc[self.current_step + 1, \"Close\"]\n",
        "                pnl = entry_price - next_close\n",
        "\n",
        "        # reward in \"pips\" => multiply by 10,000 to convert from price difference\n",
        "        reward = pnl * 10000\n",
        "        return reward\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        action is an integer in [0..(1 + 2*len(SL)*len(TP))-1],\n",
        "        where:\n",
        "          0 => do nothing\n",
        "          else => (direction, sl, tp)\n",
        "        \"\"\"\n",
        "        # Decode the action\n",
        "        direction, sl, tp = self.action_map[action]\n",
        "\n",
        "        if direction is None:\n",
        "            # No trade => reward=0\n",
        "            reward = 0.0\n",
        "            exit_price = None\n",
        "            self.last_trade_info = {\n",
        "                \"entry_price\": None,\n",
        "                \"exit_price\": None,\n",
        "                \"pnl\": 0.0\n",
        "            }\n",
        "        else:\n",
        "            # direction=0 or 1 => short/long\n",
        "            entry_price = self.df.loc[self.current_step, \"Close\"]\n",
        "            reward = self._calculate_reward(direction, sl, tp)\n",
        "\n",
        "            # next bar's close if possible\n",
        "            if self.current_step < self.n_steps - 1:\n",
        "                exit_price = self.df.loc[self.current_step + 1, \"Close\"]\n",
        "            else:\n",
        "                exit_price = entry_price\n",
        "\n",
        "            self.last_trade_info = {\n",
        "                \"entry_price\": entry_price,\n",
        "                \"exit_price\": exit_price,\n",
        "                \"pnl\": reward / 10000.0  # convert back to 'pips'\n",
        "            }\n",
        "\n",
        "            # Update equity\n",
        "            self.equity += reward\n",
        "\n",
        "        # Log equity (if no trade => equity stays same)\n",
        "        self.equity_curve.append(self.equity)\n",
        "\n",
        "        # Move forward\n",
        "        self.current_step += 1\n",
        "        if self.current_step >= self.n_steps - 1:\n",
        "            self.done = True\n",
        "        else:\n",
        "            self.done = False\n",
        "\n",
        "        # Observe next state\n",
        "        obs = self._get_observation()\n",
        "\n",
        "        return obs, reward, self.done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = self.window_size  # start so we have a full window\n",
        "        self.equity = 10000.0\n",
        "        self.done = False\n",
        "        self.equity_curve = []\n",
        "        self.last_trade_info = None\n",
        "        return self._get_observation()\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        \"\"\"Optional: print or plot debug info.\"\"\"\n",
        "        print(f\"Step: {self.current_step}, Equity: {self.equity}\")"
      ],
      "metadata": {
        "id": "fh7Ke2c5x9a7"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}